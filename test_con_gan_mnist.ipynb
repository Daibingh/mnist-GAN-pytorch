{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob2 import glob\n",
    "import warnings\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "data_path = 'E:\\\\dl-learning\\\\pytorch\\\\pytorch-examples\\\\data\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "pixel_mean = 33.32\n",
    "pixel_std = 78.57\n",
    "dataset = torchvision.datasets.MNIST(data_path, download=False)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistDataset:\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=5):\n",
    "        self._data = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_samples = len(dataset)\n",
    "        self._index = np.arange(self.num_samples)\n",
    "        mod = self.num_samples % batch_size\n",
    "        if mod > 0:\n",
    "            self._index = np.hstack((self._index, np.random.choice(self._index, batch_size-mod)))\n",
    "        self._idx_bat = [self._index[i:i+self.batch_size] for i in np.arange(0, self.num_samples, self.batch_size)]\n",
    "        \n",
    "    def shuffle_data(self):\n",
    "        np.random.shuffle(self._index)\n",
    "        self._idx_bat = [self._index[i:i+self.batch_size] for i in np.arange(0, self.num_samples, self.batch_size)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(self.num_samples/self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = []\n",
    "        label = []\n",
    "        for i in self._idx_bat[idx]:\n",
    "            x, y = self._data[i]\n",
    "            x = (np.asarray(x).astype('float')-pixel_mean)/pixel_std  # 归一化 mean=0, std=1\n",
    "            x = .5*x+.5\n",
    "            image.append(torch.tensor(x.reshape(1,28,28), dtype=torch.float32))\n",
    "            label.append(y)\n",
    "        image = torch.stack(image)\n",
    "        label = torch.tensor(label)\n",
    "        return image, label\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnistdata = MnistDataset(dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t=torch.zeros(5,10)\n",
    "# cls=mnistdata[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t[range(5),cls]=1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelG(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        self.z_dim = z_dim\n",
    "        super(ModelG, self).__init__()\n",
    "        self.fc2 = nn.Linear(10, 1000)\n",
    "        self.fc = nn.Linear(self.z_dim+1000, 64*28*28)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.deconv1 = nn.ConvTranspose2d(64, 32, 5, 1, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.deconv2 = nn.ConvTranspose2d(32, 1, 5, 1, 2)\n",
    "        self.bn3 = nn.BatchNorm2d(1)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        x: (batch_size, z_dim)\n",
    "        labels: (batch_size, 10)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        y_ = self.fc2(labels)  # (b, 10)->(b,1000)\n",
    "        y_ = F.relu(y_)\n",
    "        x = torch.cat([x, y_], 1)  # (b,1000)+(b,z_dim)->(b, 1000+z_dim)\n",
    "        x = self.fc(x)  # (b, 1000+z_dim)->(b, 64*28*28)\n",
    "        x = x.view(batch_size, 64, 28, 28)  # (b, 64*28*28)->(b, 64, 28, 28)\n",
    "        x = self.bn1(x) \n",
    "        x = F.relu(x)\n",
    "        x = self.deconv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.deconv2(x)\n",
    "        self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class ModelD(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ModelD, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, 1, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5, 1, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.fc1  = nn.Linear(64*28*28+1000, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 1)\n",
    "        self.fc3 = nn.Linear(10, 1000)\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        \"\"\"\n",
    "        x: (b, 1, 28, 28)\n",
    "        labels: (b, 10)\n",
    "        \"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        x = self.conv1(x)  # (b, 1, 28, 28)->(b, 32, 28, 28)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)  # (b, 32, 28, 28)->(b, 64, 28, 28)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(batch_size, 64*28*28)  # (b, 64, 28, 28)->(b, 64*28*28)\n",
    "        y_ = self.fc3(labels)  # (b, 10)->(b, 1000)\n",
    "        y_ = F.relu(y_)\n",
    "        x = torch.cat([x, y_], 1)  # (b, 1000)+(b, 64*28*28)->(64*28*28+1000, 1024)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)  # (b,1024)->(b,1)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z_dim=8\n",
    "# z = torch.randn(1,8)\n",
    "# label = torch.zeros(1,10)\n",
    "# label[0]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G = ModelG(z_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_out = G(z, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D=ModelD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_out = D(g_out, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 1\n",
    "epochs = 1\n",
    "# lr = .0005\n",
    "lr_d = .001\n",
    "lr_g = .001\n",
    "batch_size = 64\n",
    "latent_dim = 32\n",
    "\n",
    "\n",
    "def calc_acc(pred, true, th=.5):\n",
    "    with torch.no_grad():\n",
    "        pred = pred>th\n",
    "        true = true.byte()\n",
    "        return (pred==true).float().mean()\n",
    "    \n",
    "\n",
    "def to_onehot(label, cls=10):\n",
    "    onehot = torch.zeros(label.shape[0], cls)\n",
    "    onehot[range(label.shape[0]), label]=1.0\n",
    "    return onehot\n",
    "\n",
    "def to_onehot_fake(label, cls=10):\n",
    "    fake_label = [np.random.choice(list(set(range(cls))-set([i]))) for i in label]\n",
    "    onehot = torch.zeros(label.shape[0], cls)\n",
    "    onehot[range(label.shape[0]), fake_label]=1.0\n",
    "    return onehot\n",
    "\n",
    "def inplace_relu(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('ReLU') != -1:\n",
    "        m.inplace=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938\n"
     ]
    }
   ],
   "source": [
    "mnistdata = MnistDataset(dataset, batch_size=batch_size)\n",
    "num_iters = len(mnistdata)\n",
    "print(num_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "netG = ModelG(latent_dim).to(device)\n",
    "netD = ModelD().to(device)\n",
    "# netG.apply(inplace_relu)\n",
    "# netD.apply(inplace_relu)\n",
    "\n",
    "real_label = 1\n",
    "fake_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = optim.SGD(netG.parameters(),lr=lr_g)\n",
    "optimizer_D = optim.SGD(netD.parameters(),lr=lr_d)\n",
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_vector = torch.randn(5,latent_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/1][938/938]  loss_D: (0.678,0.714,0.004)  loss_G: 5.528  acc_D: (0.656,0.3441.000)  acc_G: 0.000\r"
     ]
    }
   ],
   "source": [
    "y_true = torch.zeros(batch_size).to(device)\n",
    "\n",
    "for i in range(start_epoch, start_epoch+epochs):\n",
    "    mnistdata.shuffle_data()\n",
    "    for j in range(num_iters):\n",
    "        \n",
    "        optimizer_D.zero_grad()\n",
    "        \n",
    "        image = mnistdata[j][0].to(device)\n",
    "        label = to_onehot(mnistdata[j][1]).to(device)\n",
    "        y_pred = netD(image, label)\n",
    "        y_true.fill_(real_label)\n",
    "        loss_D = bce_loss(y_pred.view(-1), y_true)\n",
    "        loss_d_real = loss_D.item()\n",
    "        acc_d_real = calc_acc(y_pred.view(-1), y_true)\n",
    "        loss_D.backward()\n",
    "        \n",
    "        label = to_onehot_fake(mnistdata[j][1]).to(device)\n",
    "        y_pred = netD(image, label)\n",
    "        y_true.fill_(fake_label)\n",
    "        loss_D = bce_loss(y_pred.view(-1), y_true)\n",
    "        loss_d_fake2 = loss_D.item()\n",
    "        acc_d_fake2 = calc_acc(y_pred.view(-1), y_true)\n",
    "        loss_D.backward()\n",
    "        \n",
    "        latent_vector = torch.randn(batch_size,latent_dim).to(device)\n",
    "        label = to_onehot(np.random.randint(0,10,(batch_size,))).to(device)\n",
    "        image = netG(latent_vector, label)\n",
    "        y_pred = netD(image.detach(), label)  # 非常关键 detach ！！！\n",
    "#         y_true.fill_(fake_label)\n",
    "        loss_D = bce_loss(y_pred.view(-1), y_true)\n",
    "        loss_d_fake = loss_D.item()\n",
    "        acc_d_fake = calc_acc(y_pred.view(-1), y_true)\n",
    "        loss_D.backward()\n",
    "        \n",
    "        optimizer_D.step()\n",
    "        \n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        y_pred = netD(image, label)\n",
    "        y_true.fill_(real_label)\n",
    "        loss_G = bce_loss(y_pred.view(-1), y_true)\n",
    "        acc_g = calc_acc(y_pred.view(-1), y_true)\n",
    "        loss_g = loss_G.item()\n",
    "        \n",
    "        loss_G.backward()\n",
    "        \n",
    "        optimizer_G.step()\n",
    "        \n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "        print(\"[{}/{}][{}/{}]  loss_D: ({:.3f},{:.3f},{:.3f})  loss_G: {:.3f}  acc_D: ({:.3f},{:.3f}{:.3f})  acc_G: {:.3f}\"\\\n",
    "              .format(i, start_epoch+epochs-1, j+1, num_iters, loss_d_real, loss_d_fake2, loss_d_fake, loss_g, acc_d_real, \n",
    "                      acc_d_fake2, acc_d_fake, acc_g), end='\\r')\n",
    "        \n",
    "#     gen_img = netG(fixed_vector).detach().cpu().numpy().reshape(5,28,28)\n",
    "#     mer_img = np.hstack([i for i in gen_img])\n",
    "#     im = PIL.Image.fromarray((mer_img*255).astype('uint8'))\n",
    "#     im.save('mnist_gan/{:0>3d}.png'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=image.detach().cpu().numpy().reshape(batch_size,28,28)\n",
    "lab=label.detach().cpu().numpy().reshape(batch_size,10).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, '3')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAALSklEQVR4nO3dXYhc93nH8e+vVnJj+0KuK6HaTq0G00IDdYoxlJqiXiR13Qs5Fyn2lUJaNoS6JHcx6UUMIZCWNoVetCATE/XNIdRxLUyoY9ykTm+CJePYUlS/NFYSRYuE0YUdAnmxn17sUdhIuzvredkz9vP9wDIzR7MzD4O+OueMdvafqkLS298vjT2ApJ1h7FITxi41YexSE8YuNWHsUhPGLjVh7NpQkn9Jsprk1SQvJPmzsWfSbOIP1WgjSX4LeKmqfpzkN4GvA39cVcfHnUzTcs+uDVXVyar68cWbw9e7RxxJMzJ2bSrJPyT5EfC/wCrwlZFH0gw8jNeWklwB/C5wAPirqvrpuBNpWu7ZtaWqer2q/ge4Hvjo2PNoesau7dqF5+xvacauyyTZk+SuJFcluSLJHwJ3A/819myanufsukySXwH+Hfht1nYI3wX+vqruH3UwzcTYpSY8jJeaMHapCWOXmjB2qYldO/lkSXw3UFqwqspG22fasye5PcnzSV5Kcu8sjyVpsab+r7fhZ6ZfAN4HnAGeAu6uqm9v8T3u2aUFW8Se/VbWPu/8nar6CfBF4OAMjydpgWaJ/Trg++tunxm2/YIkK0mOJTk2w3NJmtEsb9BtdKhw2WF6VR0GDoOH8dKYZtmznwFuWHf7euDsbONIWpRZYn8KuCnJ/iTvBO4Cjs5nLEnzNvVhfFX9LMk9wGPAFcADVXVybpNJmqsd/dSb5+zS4i3kh2okvXUYu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71MTU67MDJDkNvAa8Dvysqm6Zx1CS5m+m2Ad/UFWvzOFxJC2Qh/FSE7PGXsBXkxxPsrLRHZKsJDmW5NiMzyVpBqmq6b85+dWqOptkD/A48BdV9eQW95/+ySRtS1Vlo+0z7dmr6uxweR54GLh1lseTtDhTx57kyiRXX7wOvB84Ma/BJM3XLO/G7wUeTnLxcf6tqv5zLlNJmruZztnf9JN5zi4t3ELO2SW9dRi71ISxS00Yu9SEsUtNzOODMFI7L7/88pZ/vn///h2aZPvcs0tNGLvUhLFLTRi71ISxS00Yu9SEsUtN+Kk3aclManL4WPlW3++n3qTOjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJvy98dKSmfR59WlN3LMneSDJ+SQn1m27JsnjSV4cLncvZDpJc7Odw/gvALdfsu1e4Imqugl4YrgtaYlNjL2qngQuXLL5IHBkuH4EuHPOc0mas2nP2fdW1SpAVa0m2bPZHZOsACtTPo+kOVn4G3RVdRg4DP7CSWlM0/7X27kk+wCGy/PzG0nSIkwb+1Hg0HD9EPDIfMaRtCgTf298kgeBA8C1wDngU8B/AF8C3gV8D/hgVV36Jt5Gj+VhvLRgm/3eeBeJkN5mXCRCas7YpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJibGnuSBJOeTnFi37b4kP0jyzPB1x2LHlDSr7ezZvwDcvsH2v6uqm4evr8x3LEnzNjH2qnoSuLADs0haoFnO2e9J8uxwmL97szslWUlyLMmxGZ5L0oxSVZPvlNwIPFpV7xlu7wVeAQr4NLCvqj68jceZ/GSSZlJV2Wj7VHv2qjpXVa9X1RvA/cCtswwnafGmij3JvnU3PwCc2Oy+kpbDrkl3SPIgcAC4NskZ4FPAgSQ3s3YYfxr4yAJnlDQH2zpnn9uTec4uLdxcz9klvfUYu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTUyMPckNSb6W5FSSk0k+Nmy/JsnjSV4cLncvflxJ05q4ZHOSfcC+qno6ydXAceBO4EPAhar6bJJ7gd1V9YkJj+WSzdKCTb1kc1WtVtXTw/XXgFPAdcBB4MhwtyOs/QMgaUm9qXP2JDcC7wW+CeytqlVY+wcB2DPv4STNz67t3jHJVcBDwMer6tVkwyOFjb5vBViZbjxJ8zLxnB0gyTuAR4HHqupzw7bngQNVtTqc13+9qn5jwuN4zi4t2NTn7FnbhX8eOHUx9MFR4NBw/RDwyKxDSlqc7bwbfxvwDeA54I1h8ydZO2//EvAu4HvAB6vqwoTHcs8uLdhme/ZtHcbPi7FLizf1Ybyktwdjl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmpgYe5IbknwtyakkJ5N8bNh+X5IfJHlm+Lpj8eNKmtbE9dmT7AP2VdXTSa4GjgN3An8C/LCq/mbbT+b67NLCbbY++65tfOMqsDpcfy3JKeC6+Y4nadHe1Dl7khuB9wLfHDbdk+TZJA8k2b3J96wkOZbk2EyTSprJxMP4n98xuQr4b+AzVfXlJHuBV4ACPs3aof6HJzyGh/HSgm12GL+t2JO8A3gUeKyqPrfBn98IPFpV75nwOMYuLdhmsW/n3fgAnwdOrQ99eOPuog8AJ2YdUtLibOfd+NuAbwDPAW8Mmz8J3A3czNph/GngI8ObeVs9lnt2acFmOoyfF2OXFm/qw3hJbw/GLjVh7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjUx8RdOztkrwHfX3b522LaMlnW2ZZ0LnG1a85zt1zb7gx39PPtlT54cq6pbRhtgC8s627LOBc42rZ2azcN4qQljl5oYO/bDIz//VpZ1tmWdC5xtWjsy26jn7JJ2zth7dkk7xNilJkaJPcntSZ5P8lKSe8eYYTNJTid5bliGetT16YY19M4nObFu2zVJHk/y4nC54Rp7I822FMt4b7HM+Kiv3djLn+/4OXuSK4AXgPcBZ4CngLur6ts7OsgmkpwGbqmq0X8AI8nvAz8E/uni0lpJ/hq4UFWfHf6h3F1Vn1iS2e7jTS7jvaDZNltm/EOM+NrNc/nzaYyxZ78VeKmqvlNVPwG+CBwcYY6lV1VPAhcu2XwQODJcP8LaX5Ydt8lsS6GqVqvq6eH6a8DFZcZHfe22mGtHjBH7dcD3190+w3Kt917AV5McT7Iy9jAb2Htxma3hcs/I81xq4jLeO+mSZcaX5rWbZvnzWY0R+0ZL0yzT///9XlX9DvBHwJ8Ph6vann8E3s3aGoCrwN+OOcywzPhDwMer6tUxZ1lvg7l25HUbI/YzwA3rbl8PnB1hjg1V1dnh8jzwMGunHcvk3MUVdIfL8yPP83NVda6qXq+qN4D7GfG1G5YZfwj416r68rB59Nduo7l26nUbI/angJuS7E/yTuAu4OgIc1wmyZXDGyckuRJ4P8u3FPVR4NBw/RDwyIiz/IJlWcZ7s2XGGfm1G33586ra8S/gDtbekf8/4C/HmGGTuX4d+NbwdXLs2YAHWTus+ylrR0R/Cvwy8ATw4nB5zRLN9s+sLe39LGth7RtptttYOzV8Fnhm+Lpj7Ndui7l25HXzx2WlJvwJOqkJY5eaMHapCWOXmjB2qQljl5owdqmJ/wdjzrjqrAv61gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = np.random.randint(0,batch_size)\n",
    "plt.imshow(img[ind], cmap='gray')\n",
    "plt.title(str(lab[ind]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21d3824c908>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAKkklEQVR4nO3dQYycd3nH8e+vNlxCpDpNYzkhEKhy4xBQlEujKj2A0lwcDlTkZATScmgqeiOiByIhJFS19FjJiAi3okFISRorqgpRhAgnlE0UEgcLkiIXjC2byKCGE3Xy9LCvo8XZ3dnMzDvvhOf7kVYz8+7svI9G/nred2btf6oKSX/4/mjqASSthrFLTRi71ISxS00Yu9TEwVXuLIlv/Usjq6rstH2hV/Ykdyf5SZJXkjywyGNJGlfm/Zw9yQHgp8BHgbPAM8B9VfXjPX7GV3ZpZGO8st8BvFJVP6uq3wHfAo4u8HiSRrRI7DcBv9h2++yw7fck2UiymWRzgX1JWtAib9DtdKjwlsP0qjoOHAcP46UpLfLKfha4edvt9wLnFhtH0lgWif0Z4NYkH0jybuCTwMnljCVp2eY+jK+qy0nuB74DHAAeqqqXljaZpKWa+6O3uXbmObs0ulF+qUbSO4exS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTRi71ISxS00Yu9SEsUtNGLvUhLFLTcy9PjtAkjPAa8DrwOWqun0ZQ0lavoViH/xlVb26hMeRNCIP46UmFo29gO8meTbJxk53SLKRZDPJ5oL7krSAVNX8P5zcWFXnktwAPAn8bVU9vcf959+ZpH2pquy0faFX9qo6N1xeBB4D7ljk8SSNZ+7Yk1yT5Nor14GPAaeWNZik5Vrk3fjDwGNJrjzOv1fVfy1lKklLt9A5+9vemefs0uhGOWeX9M5h7FITxi41YexSE8YuNWHsUhPGLjVh7FITxi41YexSE8YuNWHsUhPGLjWxjP9wUtISXb58ec/vHzw4X7a+sktNGLvUhLFLTRi71ISxS00Yu9SEsUtN+Dm7tGYOHDgwyuP6yi41YexSE8YuNWHsUhPGLjVh7FITxi414efs0poZlkFfupmv7EkeSnIxyalt265L8mSSl4fLQ6NMJ2lp9nMY/w3g7qu2PQA8VVW3Ak8NtyWtsZmxV9XTwKWrNh8FTgzXTwD3LnkuSUs27zn74ao6D1BV55PcsNsdk2wAG3PuR9KSjP4GXVUdB44DJKmx9ydpZ/N+9HYhyRGA4fLi8kaSNIZ5Yz8JHBuuHwMeX844ksaSqr2PrJM8DNwFXA9cAL4I/AfwbeB9wM+BT1TV1W/i7fRYHsZLI6uqHT+onxn7Mhm7NL7dYvfXZaUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWpiZuxJHkpyMcmpbdseTPLLJM8PX/eMO6akRe3nlf0bwN07bP/nqrpt+PrP5Y4ladlmxl5VTwOXVjCLpBEtcs5+f5IXhsP8Q7vdKclGks0kmwvsS9KCUlWz75TcAjxRVR8abh8GXgUK+BJwpKo+vY/Hmb0zSQupquy0fa5X9qq6UFWvV9UbwNeAOxYZTtL45oo9yZFtNz8OnNrtvpLWw8FZd0jyMHAXcH2Ss8AXgbuS3MbWYfwZ4LMjzihpCfZ1zr60nXnOLo1uqefskt55jF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWrC2KUmjF1qwtilJoxdasLYpSaMXWpiZuxJbk7yvSSnk7yU5HPD9uuSPJnk5eHy0PjjSprXzPXZkxwBjlTVc0muBZ4F7gU+BVyqqq8keQA4VFWfn/FYrs8ujWzu9dmr6nxVPTdcfw04DdwEHAVODHc7wdZfAJLW1MG3c+cktwAfBn4IHK6q87D1F0KSG3b5mQ1gY7ExJS1q5mH8m3dM3gN8H/hyVT2a5DdV9cfbvv/rqtrzvN3DeGl8cx/GAyR5F/AI8M2qenTYfGE4n79yXn9xGYNKGsd+3o0P8HXgdFV9ddu3TgLHhuvHgMeXP56kZdnPu/F3Aj8AXgTeGDZ/ga3z9m8D7wN+Dnyiqi7NeCwP46WR7XYYv+9z9mUwdml8C52zS3rnM3apCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5owdqkJY5eaMHapCWOXmjB2qQljl5rYz/rsNyf5XpLTSV5K8rlh+4NJfpnk+eHrnvHHlTSv/azPfgQ4UlXPJbkWeBa4F/hr4LdV9Y/73plLNkuj223J5oP7+MHzwPnh+mtJTgM3LXc8SWN7W+fsSW4BPgz8cNh0f5IXkjyU5NAuP7ORZDPJ5kKTSlrIzMP4N++YvAf4PvDlqno0yWHgVaCAL7F1qP/pGY/hYbw0st0O4/cVe5J3AU8A36mqr+7w/VuAJ6rqQzMex9ilke0W+37ejQ/wdeD09tCHN+6u+DhwatEhJY1nP+/G3wn8AHgReGPY/AXgPuA2tg7jzwCfHd7M2+uxfGWXRrbQYfyyGLs0vrkP4yX9YTB2qQljl5owdqkJY5eaMHapiZn/EEbq6MYbb9zz++fOnVvRJMvjK7vUhLFLTRi71ISxS00Yu9SEsUtNGLvUxKr/ieuvgP/Ztul6tv5rq3W0rrOt61zgbPNa5mzvr6o/3ekbK439LTtPNqvq9skG2MO6zrauc4GzzWtVs3kYLzVh7FITU8d+fOL972VdZ1vXucDZ5rWS2SY9Z5e0OlO/sktaEWOXmpgk9iR3J/lJkleSPDDFDLtJcibJi8My1JOuTzesoXcxyalt265L8mSSl4fLHdfYm2i2tVjGe49lxid97qZe/nzl5+xJDgA/BT4KnAWeAe6rqh+vdJBdJDkD3F5Vk/8CRpK/AH4L/OuVpbWS/ANwqaq+MvxFeaiqPr8msz3I21zGe6TZdltm/FNM+Nwtc/nzeUzxyn4H8EpV/ayqfgd8Czg6wRxrr6qeBi5dtfkocGK4foKtPywrt8tsa6GqzlfVc8P114Ary4xP+tztMddKTBH7TcAvtt0+y3qt917Ad5M8m2Rj6mF2cPjKMlvD5Q0Tz3O1mct4r9JVy4yvzXM3z/Lni5oi9p2Wplmnz//+vKo+AvwV8DfD4ar251+AP2NrDcDzwD9NOcywzPgjwN9V1f9OOct2O8y1kudtitjPAjdvu/1eYG3+976qOjdcXgQeY+u0Y51cuLKC7nB5ceJ53lRVF6rq9ap6A/gaEz53wzLjjwDfrKpHh82TP3c7zbWq522K2J8Bbk3ygSTvBj4JnJxgjrdIcs3wxglJrgE+xvotRX0SODZcPwY8PuEsv2ddlvHebZlxJn7uJl/+vKpW/gXcw9Y78v8N/P0UM+wy1weBHw1fL009G/AwW4d1/8fWEdFngD8BngJeHi6vW6PZ/o2tpb1fYCusIxPNdidbp4YvAM8PX/dM/dztMddKnjd/XVZqwt+gk5owdqkJY5eaMHapCWOXmjB2qQljl5r4f4Vwe+PYFTBJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.randn(1, latent_dim).to(device)\n",
    "l = torch.zeros(1, 10).to(device)\n",
    "l[0,np.random.randint(0,10)]=1\n",
    "img = netG(x,l).detach().cpu().numpy()\n",
    "\n",
    "plt.imshow(img[0][0], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
